{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb23512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f636d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8bfc75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SSSSS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSSSSS\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Dataframe\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../dataset_smote.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SSSSS' is not defined"
     ]
    }
   ],
   "source": [
    "SSSSS\n",
    "#Dataframe\n",
    "df =pd.read_csv('../dataset_smote.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb739c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparation des features (X) et de la variable cible (y)\n",
    "X = df.drop('isFraud', axis=1)\n",
    "y = df['isFraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92282659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement, de validation et de test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01269839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Entraînement du modèle SVM\n",
    "svm_model = SVC(kernel='linear', random_state=2)\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc5ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Prédiction sur l'ensemble de validation\n",
    "\n",
    "y_pred_validation = svm_model.predict(X_validation)\n",
    "\n",
    "# Calcul des métriques sur l'ensemble de validation\n",
    "accuracy_validation = accuracy_score(y_validation, y_pred_validation)\n",
    "precision_validation = precision_score(y_validation, y_pred_validation)\n",
    "recall_validation = recall_score(y_validation, y_pred_validation)\n",
    "f1_validation = f1_score(y_validation, y_pred_validation)\n",
    "\n",
    "# Affichage des métriques sur l'ensemble de validation\n",
    "print(\"Métriques sur l'ensemble de validation:\")\n",
    "print(f\"Accuracy: {accuracy_validation:.2f}\")\n",
    "print(f\"Precision: {precision_validation:.2f}\")\n",
    "print(f\"Recall: {recall_validation:.2f}\")\n",
    "print(f\"F1-Score: {f1_validation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a62de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prédiction sur l'ensemble de test\n",
    "\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques sur l'ensemble de test\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test)\n",
    "rec = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "svm_results = pd.DataFrame([['SVM', acc,prec,rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Sauvegardez le DataFrame dans un fichier CSV\n",
    "svm_results.to_csv('../evaluations/svm_results.csv', index=False)\n",
    "\n",
    "svm_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion sur l'ensemble de test\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Non Fraud', 'Fraud'], yticklabels=['Non Fraud', 'Fraud'])\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Vraie Valeur')\n",
    "plt.title('Matrice de Confusion sur l\\'ensemble de test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c26e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbf31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
